{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "83f96d9b",
      "metadata": {
        "id": "83f96d9b"
      },
      "source": [
        "<h1 align=center><font size = 6>Building X-Ray Classification Convolutional Neural Network Model</font></h1>\n",
        "\n",
        "<br>\n",
        "\n",
        "<img  src=\"https://www.arterys.com/hubfs/1414788_ChestMSKAI-Images---Arterys_Stockimage5_GIF_071822.gif\"  height=450  width=1000  alt=\"britannica.com\">\n",
        "\n",
        "<small>Picture Source:<a  href=\"https://www.arterys.com/\"> arterys.com</a>\n",
        "\n",
        "<br>\n",
        "\n",
        "<h2>Statement</h2>\n",
        "\n",
        "<p>Within the classification study; there are two different results, in other words, two different output layer results such as <i>PNEUMONIA</i> or <i>NORMAL</i>. Since the study was carried out with a binary dataset, the trained model was compiled with <i>binary_crossentropy</i> loss function. For understanding the methodology you are free to visit the <a  href=\"https://poloclub.github.io/cnn-explainer/\">CNN Explainer</a> website. </p>\n",
        "\n",
        "<p>There are lung X-ray images of people suffering from pneumonia and healthy people. The model was developed with the <i>convolutional neural networks</i> method in line with the images downloaded from <a  href=\"https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\">Kaggle</a>. The web page was created to integrate the created model with the Flask. In addition, it is aimed to give information about the model and disease on the web page. Users will be able to evaluate themselves in line with their knowledge, show their own <i>X-ray</i> images and understand whether they are suffering from the disease. </p>\n",
        "\n",
        "<br>\n",
        "\n",
        "<h2>Dataset</h2>\n",
        "\n",
        "<h3>Content</h3>\n",
        "\n",
        "<p>The dataset is organized into 3 folders <i>(train, test, val)</i> and contains subfolders for each image category <i>(Pneumonia/Normal)</i>. There are <i>5,863 X-Ray</i> images <i>(JPEG)</i> and 2 categories </i>(Pneumonia/Normal)</i>.\n",
        "\n",
        "<i>Chest X-ray</i> images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old from <b>Guangzhou Women and Childrenâ€™s Medical Center, Guangzhou</b>. All chest <i>X-ray</i> imaging was performed as part of patients routine clinical care. For the analysis of chest <i>X-ray</i> images, all chest radiographs were initially screened for quality control by removing all low quality or unreadable scans. The diagnoses for the images were then graded by two expert physicians before being cleared for training the AI system. In order to account for any grading errors, the evaluation set was also checked by a third expert.</p>\n",
        "\n",
        "<br>\n",
        "\n",
        "<h3>Acknowledgements</h3>\n",
        "\n",
        "<h4>Data</h4>\n",
        "<p>You can access data link on following \n",
        "<a href=\"https://data.mendeley.com/datasets/rscbjbr9sj/2\">site</a>.</p>\n",
        "\n",
        "<br>\n",
        "\n",
        "<h4>License</h4>\n",
        "\n",
        "<p>CC BY 4.0\n",
        "\n",
        "The files associated with this dataset are licensed under a Creative Commons Attribution 4.0 International license.\n",
        "\n",
        "What does this mean?\n",
        "\n",
        "You can share, copy and modify this dataset so long as you give appropriate credit, provide a link to the CC BY license, and indicate if changes were made, but you may not do so in a way that suggests the rights holder has endorsed you or your use of the dataset. Note that further permission may be required for any content within the dataset that is identified as belonging to a third party.</p>\n",
        "\n",
        "<br>  \n",
        "\n",
        "<h4>Citation</h4> \n",
        "<p>You can access citation on following \n",
        "<a  href=\"http://www.cell.com/cell/fulltext/S0092-8674(18)30154-5\">site</a>.</p>\n",
        "\n",
        "<br>\n",
        "\n",
        "<h2>Keywords</h2>\n",
        "\n",
        "<ul>\n",
        "\t<li>Computer Science</li>\n",
        "\t<li>Classification</li>\n",
        "\t<li>Radiography</li>\n",
        "\t<li>X-Ray</li>\n",
        "\t<li>Neural Networks</li>\n",
        "\t<li>Flask</li>\n",
        "\t<li>Pneumonia</li>\n",
        "</ul>\n",
        "\n",
        "<br>\n",
        "\n",
        "<h2>Table of Contents</h2>\n",
        "\n",
        "<p>The contents are listed in order below. Thank you for your interest.</p>\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "<li><a href=\"https://#import\">Import Libraries and Packages</a></li>\n",
        "<li><a href=\"https://#data_preparation\">Dataset Preparation</a></li>\n",
        "<li><a href=\"https://#compile_fit\">Compile and Fit the Model</a></li>\n",
        "<li><a href=\"https://#make_pred\">Making Predictions</a></li>\n",
        "\n",
        "<br>\n",
        "\n",
        "<p></p>\n",
        "Estimated Time Needed: <strong>10 min</strong>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22852c50",
      "metadata": {
        "id": "22852c50"
      },
      "source": [
        "<br>\n",
        "<h2 align=center id=\"import\">Import Libraries and Packages</h2>\n",
        "<p>The following are the libraries we are going to use for this lab:</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60788599",
      "metadata": {
        "id": "60788599"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import load_model\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "080c9b00",
      "metadata": {
        "id": "080c9b00"
      },
      "outputs": [],
      "source": [
        "#classifier = load_model('model.h5')\n",
        "#classifier.summary()\n",
        "start = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e11f6de",
      "metadata": {
        "id": "7e11f6de"
      },
      "source": [
        "<br>\n",
        "<h2 align=center id=\"data_preparation\">Dataset Preparation</h2>\n",
        "\n",
        "<p>We are going to separate our dataset. ImadeDataGenerator library for pictures. The difference from normal picture readings is that it evaluates the pictures one by one, not all at once and helps the <i>RAM</i> to work in a healthy way.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dff4fc4",
      "metadata": {
        "id": "4dff4fc4"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32ff898f",
      "metadata": {
        "id": "32ff898f",
        "outputId": "dcbef4cf-0722-44d0-e0b4-7952fb34ca49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "## shear_range = Side bends\n",
        "## zoom_range = Zoom\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "## target_size= 64x64 size pictures for scan.\n",
        "## class_mode= Binary set\n",
        "training_set = train_datagen.flow_from_directory(\"chest_xray/train\",\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory(\"chest_xray/test\",\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1bc338b",
      "metadata": {
        "id": "a1bc338b"
      },
      "source": [
        "<br>\n",
        "<h2 align=center id=\"compile_fit\">Compile and Fit the Model</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e3d76ce",
      "metadata": {
        "id": "0e3d76ce"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPool2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62693cfc",
      "metadata": {
        "id": "62693cfc"
      },
      "outputs": [],
      "source": [
        "classifier = Sequential()\n",
        "classifier.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
        "classifier.add(MaxPool2D(pool_size=2, strides=2))\n",
        "classifier.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "classifier.add(MaxPool2D(pool_size=2, strides=2))\n",
        "classifier.add(Flatten())\n",
        "classifier.add(Dense(units=128, activation='relu'))\n",
        "classifier.add(Dense(units=1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76bc7beb",
      "metadata": {
        "id": "76bc7beb"
      },
      "source": [
        "<p>Train convolutional neural network.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6bdf30a",
      "metadata": {
        "id": "f6bdf30a"
      },
      "outputs": [],
      "source": [
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5ff0ee7",
      "metadata": {
        "id": "d5ff0ee7",
        "outputId": "a3f31101-64e7-49c3-b013-5748d553a07a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "163/163 [==============================] - 67s 409ms/step - loss: 0.3851 - accuracy: 0.8342 - val_loss: 0.2885 - val_accuracy: 0.8798\n",
            "Epoch 2/25\n",
            "163/163 [==============================] - 60s 369ms/step - loss: 0.2219 - accuracy: 0.9070 - val_loss: 0.3036 - val_accuracy: 0.8718\n",
            "Epoch 3/25\n",
            "163/163 [==============================] - 59s 363ms/step - loss: 0.2248 - accuracy: 0.9053 - val_loss: 0.2881 - val_accuracy: 0.8734\n",
            "Epoch 4/25\n",
            "163/163 [==============================] - 58s 355ms/step - loss: 0.2061 - accuracy: 0.9189 - val_loss: 0.2661 - val_accuracy: 0.9006\n",
            "Epoch 5/25\n",
            "163/163 [==============================] - 60s 369ms/step - loss: 0.1851 - accuracy: 0.9241 - val_loss: 0.4840 - val_accuracy: 0.8301\n",
            "Epoch 6/25\n",
            "163/163 [==============================] - 62s 383ms/step - loss: 0.1727 - accuracy: 0.9304 - val_loss: 0.4411 - val_accuracy: 0.8462\n",
            "Epoch 7/25\n",
            "163/163 [==============================] - 62s 381ms/step - loss: 0.1630 - accuracy: 0.9344 - val_loss: 0.3260 - val_accuracy: 0.8782\n",
            "Epoch 8/25\n",
            "163/163 [==============================] - 60s 370ms/step - loss: 0.1529 - accuracy: 0.9408 - val_loss: 0.3249 - val_accuracy: 0.8750\n",
            "Epoch 9/25\n",
            "163/163 [==============================] - 63s 389ms/step - loss: 0.1468 - accuracy: 0.9411 - val_loss: 0.2702 - val_accuracy: 0.9071\n",
            "Epoch 10/25\n",
            "163/163 [==============================] - 67s 408ms/step - loss: 0.1384 - accuracy: 0.9492 - val_loss: 0.2680 - val_accuracy: 0.9006\n",
            "Epoch 11/25\n",
            "163/163 [==============================] - 64s 391ms/step - loss: 0.1500 - accuracy: 0.9450 - val_loss: 0.3857 - val_accuracy: 0.8718\n",
            "Epoch 12/25\n",
            "163/163 [==============================] - 63s 386ms/step - loss: 0.1418 - accuracy: 0.9457 - val_loss: 0.2942 - val_accuracy: 0.9038\n",
            "Epoch 13/25\n",
            "163/163 [==============================] - 64s 392ms/step - loss: 0.1281 - accuracy: 0.9517 - val_loss: 0.2445 - val_accuracy: 0.9087\n",
            "Epoch 14/25\n",
            "163/163 [==============================] - 59s 363ms/step - loss: 0.1297 - accuracy: 0.9538 - val_loss: 0.4553 - val_accuracy: 0.8478\n",
            "Epoch 15/25\n",
            "163/163 [==============================] - 63s 387ms/step - loss: 0.1250 - accuracy: 0.9492 - val_loss: 0.2378 - val_accuracy: 0.9119\n",
            "Epoch 16/25\n",
            "163/163 [==============================] - 62s 378ms/step - loss: 0.1224 - accuracy: 0.9544 - val_loss: 0.2282 - val_accuracy: 0.9231\n",
            "Epoch 17/25\n",
            "163/163 [==============================] - 61s 376ms/step - loss: 0.1168 - accuracy: 0.9563 - val_loss: 0.3147 - val_accuracy: 0.8942\n",
            "Epoch 18/25\n",
            "163/163 [==============================] - 62s 383ms/step - loss: 0.1177 - accuracy: 0.9559 - val_loss: 0.3257 - val_accuracy: 0.9054\n",
            "Epoch 19/25\n",
            "163/163 [==============================] - 58s 357ms/step - loss: 0.1120 - accuracy: 0.9565 - val_loss: 0.4265 - val_accuracy: 0.8734\n",
            "Epoch 20/25\n",
            "163/163 [==============================] - 62s 381ms/step - loss: 0.1187 - accuracy: 0.9540 - val_loss: 0.3941 - val_accuracy: 0.8590\n",
            "Epoch 21/25\n",
            "163/163 [==============================] - 63s 390ms/step - loss: 0.1058 - accuracy: 0.9618 - val_loss: 0.3210 - val_accuracy: 0.9054\n",
            "Epoch 22/25\n",
            "163/163 [==============================] - 63s 388ms/step - loss: 0.1129 - accuracy: 0.9557 - val_loss: 0.3299 - val_accuracy: 0.8942\n",
            "Epoch 23/25\n",
            "163/163 [==============================] - 60s 369ms/step - loss: 0.0953 - accuracy: 0.9632 - val_loss: 0.5210 - val_accuracy: 0.8558\n",
            "Epoch 24/25\n",
            "163/163 [==============================] - 69s 422ms/step - loss: 0.1018 - accuracy: 0.9649 - val_loss: 0.3769 - val_accuracy: 0.8862\n",
            "Epoch 25/25\n",
            "163/163 [==============================] - 61s 371ms/step - loss: 0.0956 - accuracy: 0.9653 - val_loss: 0.3393 - val_accuracy: 0.9054\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1f64f457d30>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cccea59",
      "metadata": {
        "id": "3cccea59"
      },
      "source": [
        "<p>Save the model</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3da56a5b",
      "metadata": {
        "id": "3da56a5b",
        "outputId": "f45e97a1-cf51-4686-94b9-4f4267b1bd57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               802944    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 813,217\n",
            "Trainable params: 813,217\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "classifier.save('model.h5')\n",
        "classifier.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bd53392",
      "metadata": {
        "id": "3bd53392"
      },
      "source": [
        "<br>\n",
        "<h2 align=center id=\"make_pred\">Making Predictions</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b077807",
      "metadata": {
        "id": "0b077807",
        "outputId": "8355b678-d63c-4fd0-db1e-1b285fe7c07e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 5s 235ms/step\n",
            "Prediction successful.\n"
          ]
        }
      ],
      "source": [
        "test_set.reset()\n",
        "pred=classifier.predict_generator(test_set, verbose=1)\n",
        "\n",
        "## Filter predictions\n",
        "pred[pred > .5] = 1\n",
        "pred[pred <= .5] = 0\n",
        "print('Prediction successful.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33af5b3d",
      "metadata": {
        "id": "33af5b3d"
      },
      "source": [
        "<br>\n",
        "<p>Let's build confusion matrix for our model's performance.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d0ff3f9",
      "metadata": {
        "id": "8d0ff3f9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "147fb81a",
      "metadata": {
        "id": "147fb81a",
        "outputId": "80cad3bd-1581-4672-bd1d-ad88ad408092"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Labels(test_labels):\n",
            "\n",
            "[1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]\n"
          ]
        }
      ],
      "source": [
        "test_labels = []\n",
        "for i in range(0, int(20)):\n",
        "    test_labels.extend(np.array(test_set[i][1]))\n",
        "print('Test Labels(test_labels):\\n')\n",
        "print(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24845612",
      "metadata": {
        "id": "24845612"
      },
      "source": [
        "<br>\n",
        "<p>How each file was estimated and compared with real data is shown:</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2eb8124",
      "metadata": {
        "id": "f2eb8124"
      },
      "outputs": [],
      "source": [
        "dosyaisimleri = test_set.filenames   \n",
        "sonuc = pd.DataFrame()\n",
        "sonuc['dosyaisimleri'] = dosyaisimleri\n",
        "sonuc['tahminler'] = pred\n",
        "sonuc['test'] = test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93ae729a",
      "metadata": {
        "id": "93ae729a",
        "outputId": "3ac6e0a8-f71a-4abe-9e08-bd915e85f4ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            " [[ 74 160]\n",
            " [123 267]]\n"
          ]
        }
      ],
      "source": [
        "cm = confusion_matrix(test_labels, pred)\n",
        "print (\"Confusion Matrix:\\n\", cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4450a08",
      "metadata": {
        "id": "d4450a08"
      },
      "source": [
        "<br>\n",
        "<p>Predictions from valitadion pictures:</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08343a1f",
      "metadata": {
        "id": "08343a1f"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49d0b2c7",
      "metadata": {
        "id": "49d0b2c7"
      },
      "source": [
        "<p>Predict <i>NORMAL</i> class:</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cd28fcb",
      "metadata": {
        "id": "4cd28fcb",
        "outputId": "734948c5-daf8-4670-8e89-2b4c4d4fe1d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Prediction of NORMAL class\n",
            "[[1.]]\n",
            "[[1.]]\n",
            "[[1.]]\n",
            "[[1.]]\n",
            "[[1.]]\n",
            "[[1.]]\n",
            "[[0.]]\n",
            "[[0.]]\n"
          ]
        }
      ],
      "source": [
        "image = image\n",
        "image_name=[1427, 1430, 1431, 1436, 1437, 1438, 1440, 1442]\n",
        "print('\\nPrediction of NORMAL class')\n",
        "for i in image_name:\n",
        "    i = str(i)\n",
        "    path = 'chest_xray/val/NORMAL/NORMAL2-IM-' + i + '-0001' + '.jpeg'\n",
        "    img = image.load_img(path, target_size=(64, 64))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0) \n",
        "    images = np.vstack([x])\n",
        "    classes_normal = classifier.predict(images, batch_size=1)\n",
        "    print(classes_normal)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f93ac96",
      "metadata": {
        "id": "0f93ac96"
      },
      "source": [
        "<p>Predict <i>PNEUMONIA</i> class:</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d397c755",
      "metadata": {
        "id": "d397c755",
        "outputId": "4ee288d2-c2e3-4ac9-f8e6-9fb541af4080"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Prediction of PNEUMONIA class\n",
            "[[1.]]\n",
            "[[1.]]\n",
            "[[1.]]\n",
            "[[1.]]\n",
            "[[1.]]\n",
            "[[1.]]\n",
            "[[1.]]\n"
          ]
        }
      ],
      "source": [
        "person=[1946, 1947, 1949, 1950, 1951, 1952, 1954]\n",
        "bacteria=[4875, 4876, 4880, 4881, 4882, 4883, 4886]\n",
        "print('\\nPrediction of PNEUMONIA class')\n",
        "for i in person:\n",
        "    index=int(person.index(i))\n",
        "    bac=bacteria[index]  \n",
        "    \n",
        "    bac = str(bac)\n",
        "    i = str(i)    \n",
        "    path = 'chest_xray/val/PNEUMONIA/person' + i + '_bacteria_'+ bac +'.jpeg'\n",
        "    img = image.load_img(path, target_size=(64, 64))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0) \n",
        "    images = np.vstack([x])\n",
        "    classes_pneumonia = classifier.predict(images, batch_size=1)\n",
        "    print(classes_pneumonia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e6ab1eb",
      "metadata": {
        "id": "4e6ab1eb",
        "outputId": "603201e1-22cd-4204-dbfb-ba2d3e0305b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Took 1857.7696058750153 seconds to classificate objects.\n"
          ]
        }
      ],
      "source": [
        "end = time.time()\n",
        "cal_time = end - start\n",
        "print(\"\\nTook {} seconds to classificate objects.\".format(cal_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Contact Me</h1>\n",
        "<p>If you have something to say to me please contact me:</p>\n",
        "\n",
        "<ul>\n",
        "  <li>Twitter: <a href=\"https://twitter.com/Doguilmak\">Doguilmak</a></li>\n",
        "  <li>Mail address: doguilmak@gmail.com</li>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "_Vg9zVW3RKLI"
      },
      "id": "_Vg9zVW3RKLI"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c2f50e7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2f50e7e",
        "outputId": "c529a5fe-ecc5-4871-c397-b9149d6d33ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Changes have been made to the project on 2022-12-16 23:35:37\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "print(f\"Changes have been made to the project on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}